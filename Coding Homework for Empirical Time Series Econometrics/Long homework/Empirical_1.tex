\documentclass[11pt]{article}

\oddsidemargin=17pt \evensidemargin=17pt
\headheight=9pt     \topmargin=26pt
\textheight=564pt   \textwidth=433.8pt

\usepackage{amsmath,amssymb,graphicx,color}
\usepackage{listings, hyperref}

\newcommand{\excise}[1]{}
\newcommand{\comment}[1]{{$\star$\sf\textbf{#1}$\star$}}

\leftmargini=5.5ex
\leftmarginii=3.5ex

%for \marginpar to fit optimally
%hoffset=-1in
\setlength\marginparwidth{2.2in}
\setlength\marginparsep{1mm}
\newcommand\red[1]{\marginpar{\vspace{-1.4ex}\footnotesize{\color{red}#1}}}
\newcommand\score[1]{\marginpar{\vspace{-2ex}\colorbox{yellow}{#1/3}}\hspace{-1ex}}
\newcommand\total[1]{\marginpar{\colorbox{yellow}{\huge #1/42}}}
\newcommand\magenta[1]{\colorbox{magenta}{$\!$#1$\!$}}
\newcommand\yellow[1]{\colorbox{yellow}{$\!$#1$\!$}}
\newcommand\green[1]{\colorbox{green}{$\!$#1$\!$}}
\newcommand\cyan[1]{\colorbox{cyan}{$\!$#1$\!$}}
\newcommand\rmagenta[1]{\red{\magenta{\phantom{:}}\,: #1}}
\newcommand\ryellow[1]{\red{\yellow{\phantom{:}}\,: #1}}
\newcommand\rgreen[1]{\red{\green{\phantom{:}}\,: #1}}
\newcommand\rcyan[1]{\red{\cyan{\phantom{:}}\,: #1}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{\mbox{}\\[-8ex]ECON612 Empirical Homework \#1, Fall 2018\\\normalsize
	Instructor: Rogier Quaedvlieg\\[-2.5ex]}
\author{Solutions by: Qingchuan Lyu\\[1ex]}
\date{Due October 4 }

\maketitle



\noindent
\textsc{Exercises}

\noindent 1. \textit{Solutions}: (a). First, we check whether it is necessary to make the data stationary. Using "import data" button, I load data (S\&P500.csv) into matlab:

\begin{lstlisting}
>> y=sp500(:, 2) %select the variable "Open"
>> Y=table2array(y);
>> autocorr(Y)
\end{lstlisting}
\includegraphics[scale=.6]{ep1_q1a.jpg}

From this graph, clearly the variable "Open" is not covariance--stationary. Let's take log--difference:

\begin{lstlisting}
>> logopen=diff(log(Y));
\end{lstlisting}

(b). \begin{lstlisting}
>> plot(logopen), xlabel('observation number'), ylabel('log-difference of open')
, title('Graph of logopen')
\end{lstlisting}
\includegraphics[scale=.6]{ep1_q1b.jpg}

(c). Here is a print-out of the required function:

\begin{lstlisting}
function summary=sum_stats(x)
[h,p]=jbtest(x); %perform Jarque-Bera test statistic and p-value
summary=[mean(x), median(x), max(x), min(x), std(x), ...
    skewness(x), kurtosis(x), h,p]; %create a vector of required summary stats
\end{lstlisting}

The data I use is the log--difference of "open" in $S\&P 500$ stock index (1/1/1995--3/1/2017, weekly) data (\href{https://finance.yahoo.com/quote/\%5EGSPC/history?period1=788947200&period2=1489820400&interval=1mo&filter=history&frequency=1mo}{link})
, which collects data at a monthly frequency from January 1995 to March 2017. The summary statistics are converted to a table in Matlab, then exported to Excel, and then load into Latex by an add-in excel2latex.

\begin{lstlisting}
>> summary = sum_stats(logopen), A = summary;
T = array2table(A,'VariableNames',{'Mean','Median','Max', 'Min', 'Std', 
'Skewness', 'Kurtosis', 'JBteststat', 'JBpvalue'})
writetable(T, 'table1.xlsx')
\end{lstlisting}
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
  \centering
  \caption{Summary Statistics of "Open"}
    \begin{tabular}{rrrrrrrrr}
    \multicolumn{1}{l}{Mean} & \multicolumn{1}{l}{Median} & \multicolumn{1}{l}{Max} & \multicolumn{1}{l}{Min} & \multicolumn{1}{l}{Std} & \multicolumn{1}{l}{Skewness} & \multicolumn{1}{l}{Kurtosis} & \multicolumn{1}{l}{JBteststat} & \multicolumn{1}{l}{JBpvalue} \\
    0     & 0.012 & 0     & -0    & 0     & -0.87921 & 4.70124 & 1     & 0.001 \\
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%


\noindent 2. \textit{Solutions}: (a). A print-out of my function \textit{simAR1} is

\begin{lstlisting}
function AR1=simAR1(phi0, phi1, sig2eps, T)
AR1=zeros(1,T);
eps=normrnd(0,sig2eps);
AR1(1)=(phi0)/(1-phi1);
for t=2:T
    AR1(t)=phi0+phi1*AR1(t-1)+eps;
end
\end{lstlisting}

(b). \begin{lstlisting}
>> AR1=simAR1(0, .8, 1, 250);
>> plot(AR1), xlabel('t'), ylabel('y_t')
\end{lstlisting}
\includegraphics[scale=.6]{simAR1.jpg}

(c). \begin{lstlisting}
>> acf=autocorr(AR1, 20) %to compute sample autocorrelation
function m=theoautocorr(lags, phi1) %to compute theoretical atutocorrelation
m=ones(1, 21);
lags=20; phi1=.8;
for i=1:lags
j=(phi1)^(i);
m(i+1)=j;
end
\end{lstlisting}

To plot graphs of sample autocorrelation and theoretical autocorrelation:

\begin{lstlisting}
>> hold on;
>> plot(acf, 'r--')
>> plot(m)
>> xlabel('lags+1')
>> ylabel('autocorrelation')
>> legend('sample','theoretical')
\end{lstlisting}
\includegraphics[scale=.6]{autocorr.jpg}

\noindent 3. \textit{Solutions}:The function $x3.m$:

\begin{lstlisting}
function y=x3(x)
y=(abs(x))^3;
\end{lstlisting}

The solution and function value at the minimum of $x3.m$:

\begin{lstlisting}
>> [X,FVAL] = fminunc(@x3,2)

Local minimum found.

Optimization completed because the size of the gradient is less than
the default value of the optimality tolerance.

<stopping criteria details>

X =
    0.0020
FVAL =
   8.3202e-09
\end{lstlisting}

(b). The minimizer is obtained at the boundary:

\begin{lstlisting}
>> [X,FVAL] = fmincon(@x3,3,-1,-1)

Local minimum found that satisfies the constraints.

Optimization completed because the objective function is non-decreasing in 
feasible directions, to within the default value of the optimality tolerance,
and constraints are satisfied to within the default value of the constraint tolerance.

<stopping criteria details>

X =
    1.0000
FVAL =
    1.0000
\end{lstlisting}

\noindent 4. \textit{Solutions}: (a) \begin{lstlisting}
M1 =
   -1.4445
>> [M1 FVAL1]=fminunc(@x4, 0)

Local minimum found.

Optimization completed because the size of the gradient is less than
the default value of the optimality tolerance.

<stopping criteria details>

M1 =
   -1.4445
FVAL1 =
   -1.4295
\end{lstlisting}

(b). \begin{lstlisting}
>> [M2 FVAL2]=fminunc(@x4, 1)

Local minimum found.

Optimization completed because the size of the gradient is less than
the default value of the optimality tolerance.

<stopping criteria details>

M2 =
    1.3819
FVAL2 =
    1.3982
\end{lstlisting}

(c). \begin{lstlisting}
>> x=linspace(-2.5, 2.5);
>> y=x4(x);
>> plot(x,y), xlabel('x'), ylabel('x4')
>> hold on;
>> plot(M1, FVAL1, 'r*')
>> plot(M2, FVAL2, 'r*')
\end{lstlisting}
\includegraphics[scale=.7]{x4.jpg}

\noindent 5. \textit{Solutions}: (a). \begin{lstlisting}
function [stat, pvalue]=LBtest(X, L)
m=mean(X);
Mdl=arima('Constant',m, 'AR', {.1,.1}, 'MA', .1,'Variance',1);
[E,V] = infer(Mdl,X); %derive residuals, assuming a linear model
ac=autocorr(E, L); %compute autocorrelations of residuals for each lag
n=size(X,1);
acfrac=zeros(1, L);
for k=1:L
    acfrac(k)=ac(k)^2 / (n-k); %compute the fraction inside of a summation
end
stat=n*(n+2)*sum(acfrac); %compute test statistic
pvalue=1-chi2cdf(stat, L-.1-.1); %compute the p-value, given L lags
\end{lstlisting}

(b). Let's use Wald test on multiple parameters.

\begin{lstlisting}
function [chistat, pvalue]=robustLBtest(X, L)
R=ones(1,L);
coef=polyfit(X,y, 1); %derive estimated coefficients in a linear model
estcov=hac(X,y); %get estimated variance-covariance matrix
n=size(X,1); %get the number of total time periods
chistat=((R*coef).')*inv(R*(estcov/n)*(R.'))*(R*coef); %compute W^2
pvalue=1-chi2cdf(chistat, L-.1-.1); %computation of p-value using cdf of chisq
\end{lstlisting}

(c). Following the three graphs in Patton's textbook, let's use the 3--month treasury bill returns (1/1/1934--8/1/2018, monthly, \href{https://fred.stlouisfed.org/series/TB3MS#0}{link}), Euro/USD exchange rate returns (10/1/2017--9/23/2018, weekly, \href{https://www.investing.com/currencies/eur-usd-historical-data}{link}) and  S\&P 500 stock index data (1/1/1995--3/1/2017, weekly, the same link in 1(c)). To compute returns in these data, we take log--differences of "price" in Euro/USD dataset, "TBSMS" in 3Mtreasurybill and "open" in sp500. Then, we generate return squared.

\begin{lstlisting}
>> TB=Mtreasurybill(:, 2);
>> TB3M=table2array(TB);
>> logTB3M=diff(log(TB3M)); %compute returns of 3-month treasury bills
>> USD=EURUSDreturns(:, 2); %select "price"
>> usd=table2array(USD);
>> logusd=diff(log(usd)); %compute returns of euro-usd exchange rate
>> Open=sp500(:, 2);
>> open=table2array(Open);
>> logopen=diff(log(open)); %compute returns of "open" in sp500
>> %to generate return squared:
>> sqlogTB3M=logTB3M.^2;
>> sqlogusd=logusd.^2;
>> sqlogopen=logopen.^2;
\end{lstlisting}

Next, let's generate sample autocorrelation functions for these returns and these return squared.

\begin{lstlisting}
>> acfTB3M=autocorr(logTB3M);
>> acfsqTB=autocorr(sqlogTB3M);
>> acfopen=autocorr(logopen);
>> acfsqopen=autocorr(sqlogopen);
>> acfusd=autocorr(logusd);
>> acfsqusd=autocorr(sqlogusd);
\end{lstlisting}

Now, we draw graphs. Since the codes are mainly the same with moderate changes on the values of LB test results, I will use my codes for the variable 'acfTB3M' as an example. 
[Note that I mistakenly used $L$ instead of $L-p-q$ as the degree of freedom of chi--square distribution to compute p--values. The p--values on the graphs were approximately correct, as $p+q=.2$ is quite small in this case. However, the typo was corrected in the original function of my answer to part (a).]
\begin{lstlisting}
>> [stat, pvalue]=LBtest(acfTB3M, 20)
>> clear title xlabel ylabel
>> str = 'LB stat=35.7755, p-value=0.0163';
>> dim = [.2 .5 .3 .3];
>> autocorr(acfTB3M), ylabel('acfTB3M'), annotation('textbox',dim,'String',
str,'FitBoxToText','on')
\end{lstlisting}

The sample ACF Plots along with LB test results are:

\includegraphics[scale=.6]{acfopen.jpg}

\includegraphics[scale=.6]{acfsqopen.jpg}

\includegraphics[scale=.6]{acfsqTB.jpg}

\includegraphics[scale=.6]{acfTB3M.jpg}

\includegraphics[scale=.6]{acfusd.jpg}

\includegraphics[scale=.6]{acfsqusd.jpg}


\end{document}
